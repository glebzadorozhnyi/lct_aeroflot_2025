{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e623354",
   "metadata": {},
   "source": [
    "# Annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b603c99",
   "metadata": {},
   "source": [
    "## SAM2 bbox annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def generate_grid_2d_num_points(\n",
    "    x_min: float, x_max: float, y_min: float, y_max: float, nx: int, ny: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate 2D grid with specified number of points in each direction.\n",
    "\n",
    "    Args:\n",
    "        x_min (float): Minimum X value.\n",
    "        x_max (float): Maximum X value.\n",
    "        y_min (float): Minimum Y value.\n",
    "        y_max (float): Maximum Y value.\n",
    "        nx (int): Number of points in X direction.\n",
    "        ny (int): Number of points in Y direction.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: (X_grid, Y_grid) meshgrid arrays.\n",
    "    \"\"\"\n",
    "    x_coords = np.linspace(x_min, x_max, nx)\n",
    "    y_coords = np.linspace(y_min, y_max, ny)\n",
    "    X, Y = np.meshgrid(x_coords, y_coords)\n",
    "    flattened = [grid.flatten() for grid in [X, Y]]\n",
    "    return np.column_stack(flattened)\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders=True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "\n",
    "def show_masks(\n",
    "    image,\n",
    "    masks,\n",
    "    scores,\n",
    "    point_coords=None,\n",
    "    box_coords=None,\n",
    "    input_labels=None,\n",
    "    borders=True,\n",
    "):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i + 1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def show_anns(anns, borders=True):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones(\n",
    "        (\n",
    "            sorted_anns[0][\"segmentation\"].shape[0],\n",
    "            sorted_anns[0][\"segmentation\"].shape[1],\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann[\"segmentation\"]\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
    "        img[m] = color_mask\n",
    "        if borders:\n",
    "            import cv2\n",
    "\n",
    "            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            # Try to smooth contours\n",
    "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "\n",
    "def mask_to_bbox(mask: np.ndarray, margin: float = 0.0) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Convert boolean mask (H,W) to bounding box (x, y, w, h).\n",
    "    \"\"\"\n",
    "    H, W = mask.shape\n",
    "    ys, xs = np.where(mask)\n",
    "    if ys.size == 0 or xs.size == 0:\n",
    "        return 0, 0, 0, 0\n",
    "    x1, x2 = int(xs.min()), int(xs.max())\n",
    "    y1, y2 = int(ys.min()), int(ys.max())\n",
    "    w = (x2 - x1) * (1 + margin)\n",
    "    h = (y2 - y1) * (1 + margin)\n",
    "    xc = (x1 + x2) / 2\n",
    "    yc = (y1 + y2) / 2\n",
    "    x1 = xc - w / 2\n",
    "    x2 = xc + w / 2\n",
    "    y1 = yc - h / 2\n",
    "    y2 = yc + h / 2\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    x2 = min(x2, W)\n",
    "    y2 = min(y2, H)\n",
    "    if x2 - x1 < 56 or y2 - y1 < 56:\n",
    "        return None\n",
    "    return int(x1), int(y1), int(x2), int(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e2534",
   "metadata": {},
   "source": [
    "### SAM2 example with center box targeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57775bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\")\n",
    "image = Image.open(\"/home/akobylin/datasets/lct_2025/6_pliers/DSCN0615.JPG\").convert(\"RGB\")\n",
    "w, h = image.size\n",
    "input_point = np.array([[w // 2, h // 2]])\n",
    "input_label = np.array([1])\n",
    "input_box = np.array([w // 4, h // 4, w // 4 + w // 2, h // 4 + h // 2])\n",
    "\n",
    "with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    predictor.set_image(np.array(image))\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=None,  # input_point,\n",
    "        point_labels=input_label,\n",
    "        box=input_box,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "best_idx = int(np.argmax(scores)) if len(scores) > 0 else 0\n",
    "chosen_mask = masks[best_idx].astype(np.uint8)\n",
    "bbox = mask_to_bbox(chosen_mask, margin=0.0)\n",
    "info = {\n",
    "    \"mask\": chosen_mask,\n",
    "    \"score\": float(scores[best_idx]) if len(scores) > 0 else None,\n",
    "    \"chosen_index\": best_idx,\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "show_mask(chosen_mask, plt.gca(), borders=False)\n",
    "show_box(bbox, plt.gca())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11507f5",
   "metadata": {},
   "source": [
    "### SAM2 example with anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94534a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "predictor = SAM2AutomaticMaskGenerator.from_pretrained(\"facebook/sam2-hiera-base-plus\")\n",
    "image = Image.open(\"/home/akobylin/datasets/lct_2025/7_shernitsa/DSCN0314.JPG\").convert(\"RGB\")\n",
    "image = image.resize((512, 512))\n",
    "\n",
    "with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    masks = predictor.generate(np.array(image))\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fbd05",
   "metadata": {},
   "source": [
    "### Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from tqdm import tqdm\n",
    "\n",
    "predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a65d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/akobylin/datasets/lct_2025\")\n",
    "labels = sorted([p.name for p in root.iterdir() if p.is_dir()])[:-2]\n",
    "print(labels)\n",
    "res = []\n",
    "for label in labels:\n",
    "    target = int(label.split(\"_\")[0]) - 1\n",
    "    paths = list((root / label).glob(\"*.JPG\"))\n",
    "    for path in tqdm(paths, desc=label):\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        w, h = image.size\n",
    "        input_point = np.array([[w // 2, h // 2]])\n",
    "        input_label = np.array([1])\n",
    "        input_box = np.array([w // 4, h // 4, w // 4 + w // 2, h // 4 + h // 2])\n",
    "\n",
    "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            predictor.set_image(np.array(image))\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=None,  # input_point,\n",
    "                point_labels=input_label,\n",
    "                box=input_box,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "        best_idx = int(np.argmax(scores)) if len(scores) > 0 else 0\n",
    "        chosen_mask = masks[best_idx].astype(np.uint8)\n",
    "        bbox = mask_to_bbox(chosen_mask, margin=0.0)\n",
    "        if bbox is not None:\n",
    "            res.append(\n",
    "                {\n",
    "                    \"path\": path.name,\n",
    "                    \"label\": label,\n",
    "                    \"target\": target,\n",
    "                    \"x0\": bbox[0],\n",
    "                    \"y0\": bbox[1],\n",
    "                    \"x1\": bbox[2],\n",
    "                    \"y1\": bbox[3],\n",
    "                }\n",
    "            )\n",
    "res_df = pd.DataFrame(res)\n",
    "print(res_df.shape)\n",
    "res_df.to_csv(root / \"annotations.csv\", index=False)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c9e71",
   "metadata": {},
   "source": [
    "## Show annotated example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/akobylin/datasets/lct_2025\")\n",
    "df = pd.read_csv(root / \"annotations.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    idx = np.random.randint(0, df.shape[0] - 1)\n",
    "    row = df.iloc[idx]\n",
    "    image = Image.open(root / row[\"label\"] / row[\"path\"]).convert(\"RGB\")\n",
    "    box = np.array([row[\"x0\"], row[\"y0\"], row[\"x1\"], row[\"y1\"]])\n",
    "    crop = image.crop(tuple(box))\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    show_box(box, plt.gca())\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(crop)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b61e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
